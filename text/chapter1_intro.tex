\begin{savequote}[8cm]
    In the beginning there was nothing, which exploded.
  \qauthor{--- Terry Pratchett, \textit{Lords and Ladies}}
\end{savequote}


% What I have is:
%   Some work on a method for demographic inference (this could be how genetic variation is a marker for demographics)
%   A novel result about a migration (how shared genetic variation can be used as information to determine history)
%   Shared genetic variation across the genome can show transcription factor networks 
%       but we haven't really shown this.
% 
%   A good way to phrase this is that I want to use machine learning and statistical inference
% methods to leverage the variation between genomes to solve outstanding problems in 
% statistical genetics, and try to integrate over the variation within the genome to understand
% to identify regulatory structures for a particular disease with a single genetic difference.. 

% So in the introduction I can talk about 
%       - What causes genetic variation between individuals
%           - What models we have for how this occurs (coalescent, generating models)
%       - How can we use variation within the genome to facilitate functional genomics?
%           - In this case, variation is much more like noise, and we have to see through it 
%               to get at biological pathways. 
% The general idea is to use machine learning to wrangle genetic variation into patterns which can be used to inform
% the pursuit of understanding biology. 
%
%
%
% Outline (goal of about 20-25 pages I guess). 
% It can be both informative and a source of noise in statistical models which seek to simplify
% to usable results.
%
%   First, need to establish the problem. What is the problem?
%       The problem is that the genome is hugely important for understanding 
%       how the human body functions at a molecular level. When things go wrong,
%       the result is disease. Some of the answers for how and why disease occurs can '
%       lie in figuring out molecular mechanisms that are disrupted by disease.  
%  and again the answers for what cuase the disease can 
%       sometimes lie in what went wrong with the genetics. Understanding how the genome is
%       organised, and how the actual sequence of base pairs relates to biological processes
% 
%   But this isn't exactly a good lead in for the second part of the thesis. The question there is more
% can we group accessible elements which are important for leukemia. Then how can we uncover the 
% similarities in these and find out what is happening on a molecular level. 
%   How can the sequence of uniquely accesible elements help us to find out what is happening in cancer?
%       So it's more like machine learning can find patterns in the sequences 
%       but the machine learning is actually just the grouping part, I'm not saying anything about the 
%       actual sequences with that. 
%       So I'm using machine learning to identify accessible sequences that are predominantly associated with
%       the leukemia samples. Does this have to do with genetic variation? Or what can I call this?
%       
%        Okay so MLL is a cancer caused by a single genetic mutation. This single mutation
%        has caused it to go from being a normal cell to being a cancerous one. What happens in the 
        % middle between the single mutation and cancer?
% 
        % Can we identify regions of the genome that are associated with the disease?  What does this have to do with Genetic variation?  
            % need a method 
%

% Okay let's try again.
%
%   Two sides of the thesis. Genetic variation between individuals and the effect of genetic variation within a single genome. For the second, take the simplest model system of a single variation. This allows us to ask all sorts of questions about the extent to which a single abherant protein can have on the regulatory structure of the entire genome, and to see how far reaching and connected these things are. One major facet of this regulation that we know about is chromatin accessibility. Can we use machine learning to identify accessible regions of DNA associated with the mutation? 
%   So what do I need to introduce?

    % This is based off of Aaron's framework
    
    % Introduction:
    %     Genetic variation causes
    %     Genetic variation between individuals and coalescent theory
    %     Impact of genetic variation within the genome: a chromosomal translocation event and mixed lineage leukemia.
    %         - 

    % Part 1: Interpreting genetic variation between individuals 
    %     Chapter 1: A particle filter for demographic inference
    %     Chapter 2: Ancient admixture 
    % Part 2: The impacts of genetic variation within a single genome
    %     Chapter 3: LDA for bulk ATAC-seq and Erythropoesis
    %     Chapter 4: LDA for MLL-r 
    %     Chapter 5: A NN for blah
    % Part 3: End matter

    % For the MLL part:
    %     Genomic regulation by chromatin conformation and accessible DNA.
    %         How is it regulated? What are the effects?
    %         Measuring it via ATAC-seq and DNA-ase seq
    %     Topic modelling (I can save this for the chapter)
    %         General idea
    %         LDA 
    %         Adjusting the algorithm for bulk ATAC-seq. (This is due to a lack of appropriate differentiation systems for single cell. )
    %     MLL leukemia biology and pathology (This can be )
    %         Also will need to introduce erythropoesis too if this will be a big part of it.
    %         Will this be a seperate chapter? Or a part of the topic modelling chapter?

    %     * My big problem is that this isn't really related to genetic variation.... It's more
    %         like finding regions associated with a cell type. 


    % page counts...
    %   intro: 10
    %   1: smc2 - 20 pages
    %   2: bm - 30 pages
    %   3: ery: 25 pages
    %   4: mll: 25
    %   5. condlusion : 10


% Introduction Outline: 

% \begin{itemize}
%     \item Genomic Sequencing Data
        
%     \begin{enumerate}
%         \item Enabling advances in Sequencing technologies
%         \item Applications of sequencing technologies
%         \begin{enumerate}
%             \item Whole genome sequencing enables us to study population variation across the globe.  (whole genome sequencing)
%             \begin{enumerate}
%                 \item Technical error and variant calling
%                 % I dont deal with this but its an important caveat
%                 \item Issues with assembly in diverse populations
%             \end{enumerate}
%             \item Functional genomics (ATAC-seq, DNAse-seq, ChIP-seq, etc.)
%             \begin{enumerate}
%                 \item 
%             \end{enumerate}
%         \end{enumerate}

%     \end{enumerate}

%     \item Machine Learning and Statistical Inference for sequencing data
%     \begin{enumerate}
%         \item Reasons for considering machine learning for these two problems.
%     \end{enumerate} 
     
%     \item \textbf{Aim}: Use sequencing data and machine learning to find new ways to answer outstanding issues at the population and cellular scale.
%     \begin{enumerate}
%         \item \textbf{Specific Aim 1}: Estimate a coloured ancestral recombination graph from WGS Data
%         \begin{enumerate}
%             \item Modelling ancestry with the coalescent
%             \item Traditional approaches to modelling demography
%             \item Sequential Monte Carlo
%             \item Advantages, including directional migration
%         \end{enumerate}
%         \item \textbf{Specific Aim 2}: Predict Regulatory Regions of MLL-AF4 Leukemia from ATAC-seq
%         \begin{enumerate}
%             \item Traditional methods for genomic sequence annotation
%             \item Artificial Neural Networks
%             \item Adopting artificial intelligence models for sequence based learning
%             \item Advantages , including in silico mutagenesis 
%         \end{enumerate}
%     \end{enumerate}
% \end{itemize}

\chapter{\label{ch:1-intro} Machine Learning and Next Generation Sequencing} 

%\minitoc

In recent years, genomics has taken front and centre stage in the search for knowledge about our physiology and our humanity. Much of this growth from the time of Mendel's peas to the current era of rapid development and global vaccination against deadly disease with messenger RNAs has come at the heels of technological developments in sequencing technologies. As we continue to explore the questions raised by the first efforts to understand what it is that makes up humanity at a molecular level, the availability of massively high-throughput sequencing has allowed for the study of our species, from its history to its pathology. Cost lowers every year, and with it, so too does the barrier to entry into genomics research. This explosion in sequencing data, concurrent with a famously exponential increase in computational processing power, has changed the way that we conduct research and philosophically approach hypothesis testing. Alogirthms designed to learn patterns directly from petabytes of freely available data prioritize biological hypotheses. This thesis broadly aims to extend the use of machine learning for next generation sequencing data in two different ways. Firstly, by learning demographic parameters from whole genome sequencing data, and secondly by learning cellular regulatory programs from collections of accessible chromatin experiments. We apply the first method to detect a substantial back migration in the ancient past, and the second to identify a subset of novel enhancer elements active in childhood KMT2A-AFF1 leukemia patients. These methods both address open questions in the field, and provide novel insight into human origins and the dysregulation of functional genomics leading to cancer.

This chapter is structured as follows. I begin by introducing next generation sequencing and its development. Next, I give context to the long-standing problem of demographic inference and how the NGS revolution has set the stage for the use of large-scale machine learning algorithms. I also briefly describe the mathematical model underpinning these methods and other comparable approaches. We then pivot to discussing the application of next generation sequencing to functional genomics and the development of \gls{atac}, \gls{chip}, and RNA sequencing. I describe previous approaches for learning from these data applied to childhood leukemias and more broadly. 

Chapter 2 introduces \gls{smc2} and applies it to the problem of detecting ancient migration into Africa.  Chapter 3 develops the \gls{blda} algorithm and demonstrates its use on simulated and real data. Chapter 4 applies BLDA to an unknown dataset of KMT2A-AFF1 patients and cell lines in an attempt to study active regulatory programs in these samples. Chapter 5 discusses the overall implications of and next steps with this research.

\section{The Evolution of Next Generation Sequencing}

The order of bases in poly-nucleotide chains simultaneously encode the instructions for protein synthesis and all information about the geneological history of an individual. Despite an understanding of the three-dimensional structure of \gls{dna} in the early 1950s, the first protein-coding gene sequence was not completed until 1972 \cite{JD1953,JOU1972}. By this point, a sequencing method developed by Fred Sanger and colleagues was giving rise to the first generation of sequencing technologies \cite{Kulkarni2014}. Sanger sequencing, and its more modern incarnation Sanger sequencing by capiliary electrophoresis, remains an important technique for clinical genomics and is the gold standard for accuracy \cite{Shendure2017}. This thesis is concerned with the analysis of data resulting from sequencing technologies, and not the mechanism of sequencing itself, so descriptions here will be brief. Sanger sequencing combines denatured single-stranded DNA molecules and a solution of nucleotides with small amounts of chain-terminating dideoxynucleotides to produce fragments of varying lengths, which can then be separated by molecular weight through electrophoresis and read either manually from a slab gel or automatically through a capillary \cite{F1977,Liu2012}. Modern iterations are capable of processing up to X samples concurrently, improving substantially over previous iterations of the technique which required manual base calling (Cite Illumina). 

In many ways, modern NGS techniques are natural extensions of the original Sanger sequencing method. The first step in an NGS workflow is library preparation \cite{Head2018}. This step involves gathering DNA or \gls{rna} from the experimental design being employed, such as \gls{wgs}, fragmenting the product to a desired length and attaching oligonucleotide adaptors to both the 3' and 5' ends of the sequence. Adaptors are attached either through ligation, where adaptors are ligated to end-repaired inserts, or by "tagmentation" where a single transposase enzyme fragments and ligates adaptors in a single step \cite{R2011}. 

There are currently four distinct methods of sequencing, in approximate order of popularity and expected read coverage:

\begin{enumerate}
    \item Sequencing by synthesis
    \item Sequencing by ligation
    \item Ion semiconductor sequencing
    \item Pyrosequencing
\end{enumerate}

% As a downside, mention that the error rates per base are much higher than with sanger sequencing \cite{Liu2012}
% Talk about long read versus short read, and arrays versus sequencing.

% dideoxynucleotides (remove 3' hydroxy group atom) stop extension, chain terminating nucleotide is identified with a fluorescent dye at the 3' end. Extension products are seperated by capiliary electrophoresis or on a slab gel traditioanlly , where an electrical field moves the DNA with a speed inversely proportional to its molecular weight. Excited terminal bases emits light which can be recorded. Remains gold standard with extremely high accuracy. Sequencing single genes, microsatellite or STR, hard to sequence regions. 

% NGS transformed this. Massively parrellel versus one forward and reverse read.  Interogating > 100 genes, low input amounts, novel variants, 

% - library obtained either by amplification or by ligation 

% - Four main methods used by NGS systems
%     - Pyrosequencing
%         - Each nucleotide incorporation releases a pyrophosphate, used in a series of reactions resulting in light which is recorded by a camera. 
%         - Comparable read lengths to sanger, but high error rates over homopolymers.
%     - sequencing by synthesis (most popular, Illumina HiSeq)
%         - illumina
%         - All 4 nucelotides are added and terminated, one binds, the base is read by fluorsence, then the attached termination and fluorsence is washed away and the process is repeated. 
%         - increased read lengths as you get longer due to incomplete deletion of the fluorsence
%     - squencing by ligation
%         - 16 oligo nucleotide probabilities
%         - adaptor is bound, and the 2 specific bases of the oligose are bound with the fluorecent probe. The probe and last 3 bases are washed away and the sequence is repeated for 5 adaptor sequences offset by one base
%         - very short reads
%     - ion semiconductor sequencing 
%         - semiconductor transistor can detect phases
%         - a single H+ is released on base incoroporation. base calling is a NN, like gerton's previous work 